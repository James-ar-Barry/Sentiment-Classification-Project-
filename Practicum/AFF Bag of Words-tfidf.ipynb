{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Model on Amazon Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from Word2VecUtility3 import Word2VecUtility3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('AFF_Evenly_Sampled.csv', sep=',', index_col=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quick look at the reviews:\n",
      "   Score                                               Text\n",
      "0      1  I like this brand. I didn't realize I was orde...\n",
      "1      1  Being my wife is a licensed cosmetologist and ...\n",
      "2      1  If you are looking for an upgrade from the sta...\n",
      "3      1  I am so allergic to too many artificial sweete...\n",
      "4      1  I have not been able to find this locally and ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    82000\n",
       "0    82000\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('A quick look at the reviews:')\n",
    "print(data.head())\n",
    "data['Score'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split dataset into train/test sets\n",
    "train_data = data.sample(frac=0.7,random_state=200)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "train_data.to_csv('train_Even82k.csv', index=False, sep=',', encoding='utf-8')\n",
    "test_data.to_csv('test_Even82k.csv', index=False, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score                                               Text\n",
      "0      1  I had been frustrated trying to figure out how...\n",
      "1      0  I tried this product in hopes that it would in...\n",
      "   Score                                               Text\n",
      "0      1  I like this brand. I didn't realize I was orde...\n",
      "1      1  If you are looking for an upgrade from the sta...\n"
     ]
    }
   ],
   "source": [
    "#load train/test sets\n",
    "train = pd.read_csv('train_Even82k.csv', index_col=False)\n",
    "test = pd.read_csv('test_Even82k.csv', index_col=False)\n",
    "\n",
    "# print (\"The number of training samples are: %r\") % (len(train))\n",
    "# print (\"The number of testing samples are: %r \\n\") % (len(test))\n",
    "\n",
    "#make sure the train/test tests are formatted correctly.\n",
    "print(train.iloc[:2])\n",
    "print(test.iloc[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing & Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the Amazon reviews...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list. Word2VecUtility is a text processing function imported from another file. \n",
    "\n",
    "print(\"Cleaning and parsing the Amazon reviews...\\n\")\n",
    "for i in range( 0, len(train[\"Text\"])):\n",
    "    clean_train_reviews.append(\" \".join(Word2VecUtility3.review_to_wordlist(train[\"Text\"][i], True)))\n",
    "\n",
    "clean_test_reviews = []\n",
    "\n",
    "print(\"Cleaning and parsing the test set reviews...\\n\")\n",
    "for i in range(0,len(test[\"Text\"])):\n",
    "    clean_test_reviews.append(\" \".join(Word2VecUtility3.review_to_wordlist(test[\"Text\"][i], True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer = TfidfVectorizer(analyzer=\"word\",tokenizer=None,preprocessor=None,stop_words=None,max_features=5000)\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tuning with GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRID SEARCH:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\james\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2', 'elasticnet'], 'alpha': [0.001, 0.0001, 1e-05, 1e-06], 'loss': ('log', 'hinge')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'loss': ('log', 'hinge'),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.001, 0.0001, 0.00001, 0.000001]\n",
    "}\n",
    "\n",
    "print()\n",
    "print(\"GRID SEARCH:\")\n",
    "grid_search = GridSearchCV(SGDClassifier(), parameters, cv=3)\n",
    "grid_search.fit(train_data_features, train['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data: 0.8903135888501742\n",
      "Best loss: hinge\n",
      "Best penalty: elasticnet\n",
      "Best alpha: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for data:', grid_search.best_score_)\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best loss:', grid_search.best_estimator_.loss)\n",
    "print('Best penalty:', grid_search.best_estimator_.penalty)\n",
    "print('Best alpha:', grid_search.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM = SGDClassifier(loss='hinge', penalty='elasticnet', alpha=1e-05, max_iter=5, random_state=42)\n",
    "SVM = SVM.fit( train_data_features, train[\"Score\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the test set reviews...\n",
      "\n",
      "Predicting test labels...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89361788617886184"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier trained using training data to test set, and view the accuracy score\n",
    "SVM.score(test_data_features, test['Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(train_data_features, train[\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86402439024390243"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_data_features, test['Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Try SVM BoW with Radomly Distributed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('AFF_Randomly_Distributed_164k.csv', sep=',', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split dataset into train/test sets\n",
    "#changed names so that we don't contaminate data \n",
    "train_data = df.sample(frac=0.7,random_state=200)\n",
    "test_data = df.drop(train_data.index)\n",
    "\n",
    "train_data.to_csv('train_Random.csv', index=False, sep=',', encoding='utf-8')\n",
    "test_data.to_csv('test_Random.csv', index=False, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples are: 114800\n",
      "The number of testing samples are: 49200 \n",
      "\n",
      "   Score                                               Text\n",
      "0      0  I was a bit disappointed with these figs.  The...\n",
      "1      1  I think the first thing that got me looking at...\n",
      "   Score                                               Text\n",
      "0      1  White Gold is the BEST honey ever!  It's smoot...\n",
      "1      0  The product itself is fine, but it is a tiny t...\n"
     ]
    }
   ],
   "source": [
    "#load train/test sets\n",
    "train1 = pd.read_csv('train_Random.csv', index_col=False)\n",
    "test1 = pd.read_csv('test_Random.csv', index_col=False)\n",
    "\n",
    "print((\"The number of training samples are: %r\") % (len(train1)))\n",
    "print((\"The number of testing samples are: %r \\n\") % (len(test1)))\n",
    "\n",
    "#make sure the train/test tests are formatted correctly.\n",
    "print(train1.iloc[:2])\n",
    "print(test1.iloc[:2])\n",
    "#print(train1['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the Amazon reviews...\n",
      "\n",
      "Cleaning and parsing the test set reviews...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews1 = []\n",
    "\n",
    "print(\"Cleaning and parsing the Amazon reviews...\\n\")\n",
    "for i in range( 0, len(train1[\"Text\"])):\n",
    "    clean_train_reviews1.append(\" \".join(Word2VecUtility3.review_to_wordlist(train1[\"Text\"][i], True)))\n",
    "\n",
    "clean_test_reviews1 = []\n",
    "\n",
    "print(\"Cleaning and parsing the test set reviews...\\n\")\n",
    "for i in range(0,len(test1[\"Text\"])):\n",
    "    clean_test_reviews1.append(\" \".join(Word2VecUtility3.review_to_wordlist(test1[\"Text\"][i], True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectorizer = TfidfVectorizer(analyzer=\"word\",tokenizer=None,preprocessor=None,stop_words=None,max_features=5000)\n",
    "\n",
    "train_data_features1 = vectorizer.fit_transform(clean_train_reviews1)\n",
    "train_data_features1 = train_data_features1.toarray()\n",
    "\n",
    "test_data_features1 = vectorizer.transform(clean_test_reviews1)\n",
    "test_data_features1 = test_data_features1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRID SEARCH:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\james\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'loss': ('log', 'hinge'), 'penalty': ['l1', 'l2', 'elasticnet'], 'alpha': [0.001, 0.0001, 1e-05, 1e-06]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'loss': ('log', 'hinge'),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.001, 0.0001, 0.00001, 0.000001]\n",
    "}\n",
    "\n",
    "print()\n",
    "print(\"GRID SEARCH:\")\n",
    "grid_search1 = GridSearchCV(SGDClassifier(), parameters, cv=3)\n",
    "grid_search1.fit(train_data_features1, train1['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data: 0.922456445993\n",
      "Best penalty: l2\n",
      "Best alpha: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for data:', grid_search1.best_score_)\n",
    "# View the best parameters for the model found using grid search\n",
    "#print('Best loss:', grid_search1.best_estimator_.loss)\n",
    "print('Best penalty:', grid_search1.best_estimator_.penalty)\n",
    "print('Best alpha:', grid_search1.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM1 = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-05, max_iter=5, random_state=42)\n",
    "SVM1 = SVM1.fit( train_data_features1, train1[\"Score\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92863821138211378"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier trained using training data to test set, and view the accuracy score\n",
    "SVM1.score(test_data_features1, test1['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM2 = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5, random_state=42)\n",
    "SVM2 = SVM2.fit( train_data_features1, train1[\"Score\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84626016260162606"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM2.score(test_data_features1, test1['Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(train_data_features1, train1[\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84626016260162606"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_data_features1, test1['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
